{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/tutorials/blob/master/nn_with_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DxM2QIF-mIg",
        "colab_type": "text"
      },
      "source": [
        "## Una Rete Neurale da Zero\n",
        "Ti svelo un segreto: non puoi usare le Reti Neurali Artificiali se non sai come funzionano le Reti Neurali. Quando ci si approccia a Deep Learning e alle Reti Neurali per la prima volta si viene subito intimoriti dalla matematica che c'è dietro e si finisce a guardare le API di Tensorflow o a fare copia-incolla di pezzi di codice presi in giro per il web.\n",
        "<br>\n",
        "Lo scopo di questo articolo è demistificare le Reti Neurali e mostrare che in fondo, se si sa come interpretarla, la matematica che c'è dietro non è nulla di terrificante.\n",
        "\n",
        "## Prerequisiti\n",
        "In questo articolo do per scontato che tu sappia cosa è e a cosa serve il Machine Learning, se così non fosse parti pure [da qui](http://blog.profession.ai/cosa-e-machine-learning/) e poi magari dai uno sguardo [a questo](http://blog.profession.ai/deep-learning-svelato-ecco-come-funzionano-le-reti-neurali-artificiali/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFhvFPCg-ja9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8yotfV6Jji2",
        "colab_type": "text"
      },
      "source": [
        "## Partiamo dalle Metriche\n",
        "Le metriche sono un'argomento generale di un qualsiasi modello Machine Learning e non limitate alle sole Reti Neurali, queste ci permettono di determinare la qualità del nostro modello comparando le predizioni da esso fornite con i risultati reali presenti all'interno del dataset. Una metrica comune per problemi di classificazione è l'**accuracy**, che indica semplicemente la percentuale di predizioni che il nostro modello ha azzeccato ed è così definita:\n",
        "\n",
        "$$ \\frac{1}{N}\\sum_{i=1}^N(\\hat{y_i}-y_i)^2 $$\n",
        "\n",
        "dove $\\hat{y}$ sono le predizioni del modello mentre $y$ sono i valori reali. Definiamo una funzione per calcolare l'accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgcHo3HZ-u-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y, y_pred):\n",
        "  return np.sum(y==y_pred)/len(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XcIIpayqBMu",
        "colab_type": "text"
      },
      "source": [
        "Uno dei limiti di questa metrica è che non tiene conto della *probabilità* che una predizione sia corretta, quindi un'errore grossolano assume lo stesso peso di un'errore minore. Per questo motivo è sempre una buona idea affiancare l'accuracy ad un altra metrica che tiene conto di questa informazione, la **Binary Cross Entropy** anche conosciuta come **Log Loss**, che è definita in questo modo:\n",
        "<br><br>\n",
        "$$ -\\frac{1}{N}\\sum_{i=1}^N(y\\cdot log(a) + (1-y)\\cdot(1-a) $$\n",
        "dove $a$ sono le probabilità di appartenenza alla classe positiva ritornate dal modello, mentre $y$ sono sempre i valori reali. Definiamo una funzione per calcolare la Log Loss:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCo02J1ptDfk",
        "colab_type": "text"
      },
      "source": [
        "### Log Loss\n",
        "$$ -\\frac{1}{N}\\sum_{i=1}^N(y\\cdot log(a) + (1-y)\\cdot(1-a) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_H9rL38_ACS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_loss(y_true, y_proba):\n",
        "  return -np.sum(y_true*np.log(y_proba)+(1-y_true)*np.log(1-y_proba))/len(y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZzRuRHsJm0M",
        "colab_type": "text"
      },
      "source": [
        "### Predizione\n",
        "Passiamo ora alla fase di predizione, in una rete neurale la predizione avviene a cascata, l'input della rete arriva allo strato di input, viene moltiplicato per i pesi dello strato e viene sommato il bias in questo modo:\n",
        "<br><br>\n",
        "$$ z_1 = W_1x+b_1 $$\n",
        "<br><br>\n",
        "ora l'output dello strato di input diventerà l'input dello strato nascosto, questo processo è conosciuto come **Forward Progation** (Propagazione in Avanti) e queste sono le sue equazioni:\n",
        "\n",
        "$ z_1 = W_1x+b_1  \\\\\n",
        " a_1 = \\phi(z_1)  \\\\\n",
        " z_2 = W_2a_1+b_2  \\\\\n",
        " a_2 = \\phi(z_2)  \\\\\n",
        "$\n",
        "\n",
        "come vedi all'output di uno strato viene applicata una funzione $\\phi$, questa funzione è chimata **funzione di attivazione** e può variare da strato a strato. Cosa è una funzione di attivazione ? Una funzione di attivazione è una funzione che ci permette di aggiungere la non linearità alla nostra rete, senza di essa una rete neurale, anche una molto profonda, porterebbe agli stessi risultati di una regressione logistica. Esistono diverse funzioni di attivazione, per gli strati nascosti la più utilizzata e la Rectified Linear Unit (ReLu) che è così definita:\n",
        "\n",
        "$$ \\text{relu}(z) = \\begin{Bmatrix} \n",
        "0  \\ \\ \\ se \\ \\  z < 0\n",
        "\\\\ \n",
        "z  \\ \\ \\ se \\ \\ z \\geq 0\n",
        "\\end{Bmatrix}\n",
        "$$\n",
        "\n",
        "Mentre per gli strati di output la funzione di attivazione da utilizzare dipende dal tipo di problema che stiamo affrontando, per una classificazione binaria bisogna usare la sigmoide, che è così definita.\n",
        "\n",
        "$$ \\text{sigmoid(z)} = \\frac{1}{1+e^{-z}} $$\n",
        "\n",
        "Implementiamo ReLu e Sigmoide in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGI4C7USKbD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(Z):\n",
        "  return np.maximum(Z, 0)\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1/(1+np.power(np.e,-Z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Caw2IEcg0Nmg",
        "colab_type": "text"
      },
      "source": [
        "Aggiungendo le corrette funzioni di attivazione, le equazioni della forward propagtion diventano le seguenti.\n",
        "\n",
        "$z_1 = W_1x+b_1 \\\\\n",
        "a_1 = \\text{relu}(z_1) \\\\\n",
        "z_2 = W_2a_1+b_2 \\\\\n",
        "a_2 = \\text{sigmoid}(z_2) \\\\\n",
        "$\n",
        "\n",
        "Usiamo le equazioni per implementare la forward propagation in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf5xhTBf2UXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, W1, b1, W2, b2):\n",
        "  \n",
        "  global cache\n",
        "  \n",
        "  Z1 = np.dot(X,W1)+b1\n",
        "  \n",
        "  A1 = relu(Z1)\n",
        "  Z2 = np.dot(A1,W2)+b2\n",
        "  A2 = sigmoid(Z2)\n",
        "  \n",
        "  cache = (Z1, A1, Z2, A2)\n",
        "  \n",
        "  return A2.ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l12dsUzr2MHi",
        "colab_type": "text"
      },
      "source": [
        "L'ultimo strato ci ritornerà la probabilità che l'osservazione in input appartenga alla classe positiva, una osservazione con una probabilità maggiore del 50% va classificata come appartenenza alla classe positiva, mentre un'osservazione con probabilità minore del 50% va classificata come appartenente alla classe negativa. Per standard, qualora la probabilità fosse esttamente del 50% classifichiamola come positiva, anche se non è attendibile, in ogni caso insieme ad una classificazione dobbiamo sempre prendere in considerazione la probabilità della sua corretteza.\n",
        "$$\n",
        " \\hat{y} = \\begin{Bmatrix}  \n",
        "1  \\ \\ \\ se \\ \\  a_2\\geq 0.5\n",
        "\\\\ \n",
        "0  \\ \\ \\ se \\ \\  a_2<0.5\n",
        "\\end{Bmatrix}\n",
        "$$\n",
        "\n",
        "Utilizziamo queste informazioni per creare la funzione di predizione. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei6CsZ4GJo3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, W1, b1, W2, b2):\n",
        "  proba = forward_propagation(X, W1, b1, W2, b2)\n",
        "  y = proba.copy()\n",
        "  y[y>=0.5]=1\n",
        "  y[y<0.5]=0\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LR2eIMXbL1W",
        "colab_type": "text"
      },
      "source": [
        "La fase di predizione è completa, passiamo all'addestramento, dove dovremo permettere alla nostra rete di apprendere i sui coefficienti: pesi e bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JOLOrsnJyru",
        "colab_type": "text"
      },
      "source": [
        "### Addestramento\n",
        "\n",
        "L'addestramento della maggior parte dei modelli di machine learning si basa sull'utilizzo di un algoritmo di ottimizzazione, il più utilizzato è il **Gradient Descent**.\n",
        "<br><br>\n",
        "#### Il Gradient Descent in matematichese\n",
        "\n",
        "Il funzionamento di questo algoritmo è abbastanza semplice: al valore dei coefficienti viene iterativamente sottratto il valore della corrispondente derivata parziale della funzione di costo moltiplicato per una costante, chiamata **learning rate**, e questo per un numero definito di cicli, chiamati **epoche**. Okay, detto così potrebbe non sembrare facile affatto, specialmente se non ricordi cosa è una derivata, facciamo un piccolo ripasso di analisi matematica. \n",
        "<br><br>\n",
        "#### Derivate e Gradienti: un breve ripasso\n",
        "La derivata di una funzione è un'altra funzione derivata dalla stessa funzione (e qui il nome) che indica quanto velocemente tale funzione sta crescendo/decrescendo in un determinato punto.  Se in un dato punto la funzione sta crescendo in maniera molto rapida, la sua derivata sarà un valore positivo grande, al contrario se la funzione sta descrescendo in maniera molto rapida la sua derivata sarà un valore negativo molto grande. Se invece la funzione è costante, quindi mantiene lo stesso valore, allora la derivatà varrà 0. Se una funzione ha più variabili allora ha più derivate, dato che ogni variabile può contribuire alla variazione della funzione in maniera differente, in questo caso si parla di variabili parziali, che messe insieme formano il gradiente della funzione. Ora che abbiamo rispolverato le derivate, torniamo al Gradient Descent.\n",
        "<br><br>\n",
        "#### Il Gradient Descent in italiano\n",
        "In parole povere il Gradient Descent funziona così: i valori 'ideali' dei coefficienti sono quelli che ci permettono di ottenere il valore minore per la funzione di costo, cioè quelli che la minimizzano, sommando iterativamente il valore delle rispettive derivate parziali della funzione di costo tendiamo a 'spingere' i coefficienti verso tale punto di minimo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dJ-EnsV4nuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(X, epochs=100, lr=0.01):\n",
        "     \n",
        "  for _ in range(epochs):\n",
        "    Y = predict(X, W1, b1, W2, b2)\n",
        "    dW1, db1, dW2, db2 = funzione_magica_che_calcola_le_derivate_parziali(X, W2, A1, A2, Y)\n",
        "    W1+=lr*dW1\n",
        "    b1+=lr*db1\n",
        "    W2+=lr*dW2\n",
        "    b2+=lr*db2\n",
        "    \n",
        "  return W1, b1, W2, b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ju3pUEf4xU2",
        "colab_type": "text"
      },
      "source": [
        "Learning Rate e numero di Epoche sono due dei tanti **iperparametri** di una rete neurale, cioè quei valori che tocca a noi definire manualmente. Per una rete neurale il numero di epoche andrebbe sempre impostato almeno a 100, mentre il Learning Rate va cercato in un range esponeziale che va da 0.0001 a 10.\n",
        "<br>\n",
        "Come facciamo a calcolare il gradiente, cioè le derivate parziali della funzione di costo rispetto ai vari coefficienti ? Come si dice da me \"e qua casca lo scecco\" ! Se si fosse trattato di una regressione logistica, differenziare la funzione di costo sarebbe stato un gioco da ragazzi, ma nel caso di una rete neurale è molto più complesso, infatti una rete neurale è composta da più funzioni annidate, cioè funzioni che contengono altre funzioni, se non ci credi pensa che le equazioni della forward propagation possono anche essere espresse come un'unica equazione incomprensibile, questa qui:\n",
        "<br><br>\n",
        "$$ a_2 = \\text{sigmoid}(W_2\\cdot \\text{relu}(W_1x+b_1)+b_2) $$\n",
        "<br>\n",
        "Ora noi dobbiamo riuscire a sapere quanto ogni coefficiente di ogni strato contribuisce all'errore della rete e questo problema non è per nulla banale ! Infatti gli scenziati ci si sono arrovellati sopra per 50 anni, fino al 1984, quando si arrivò ad una soluzione, la **backpropagation** (propagazione all'indietro o retropropagazione).\n",
        "#### L'algoritmo della Backpropagation\n",
        "La **backpropagation** è il processo inverso della forward propagation, questa volta l'output della rete va a ritroso dall'ultimo strato fino al primo. In realtà ad andare a ritroso non è l'output ma **l'errore** e in questo modo riusciamo a risalire a quanto ogni peso di ogni strato ha contribuito all'errore. Ma come ? Ma perché ? L'algoritmo si basa su una proprietà delle derivate, chiamata **Chain Rule** (Regola della Catena), che ci dice che la derivata di una funzione composta e pari al prodotto della derivata più esterna, avente come argomento la funzione interna, per la derivata della funzione interna. Quindi se abbiamo una funzione f(x) tale che:\n",
        "<br><br>\n",
        "$$f(x) = f(g(x)) $$\n",
        "che quindi è una funzione composta, possiamo calcolare la sua derivata come\n",
        "<br><br>\n",
        "$$\\frac{df}{dx}=\\frac{ df}{df}\\frac{dg}{dx}$$\n",
        "\n",
        "Nel nostro caso abbiamo più funzioni annidate, esattamente 4 (il numero di equazioni della forward propagation), possiamo procedere così:\n",
        "* Calcoliamo le derivate parziali della funzione di costo rispetto alla sigmoide\n",
        "* Calcoliamo le derivate parziali della sigmoide rispetto a z2\n",
        "* Calcoliamo le derivate parziali di z2 rispetto alla ReLu\n",
        "* Calcoliamo le derivate parziali della ReLu rispetto a Z1\n",
        "* Calcoliamo le derivate parizali di Z1 risetto ai coefficienti\n",
        "* Moltiplichiamo tutti insieme\n",
        "\n",
        "In forma matematichese abbiamo questo:\n",
        "<br><br>\n",
        "$$\\frac{d\\text{J}}{dw}=\\frac{d\\text{J}}{d\\sigma}\\frac{d\\sigma}{dz_2}\\frac{dz_2}{d\\text{ReLu}}\\frac{d\\text{ReLu}}{dz_1}\\frac{dz_1}{dw}$$\n",
        "<br>\n",
        "$$\\frac{d\\text{J}}{db}=\\frac{d\\text{J}}{d\\sigma}\\frac{d\\sigma}{dz_2}\\frac{dz_2}{d\\text{ReLu}}\\frac{d\\text{ReLu}}{dz_1}\\frac{dz_1}{db}$$\n",
        "\n",
        "<br>\n",
        "E come un salmone abbiamo ripercorso all'indietro la nostra rete neurale  e abbiamo ottenuto le derivate parziali della funzione di costo rispetto ai vari coefficienti. Questa ovviamente è un'equazione simbolica, per ottenere le equazioni effettive dobbiamo calcolare le varie derivate, cosa che ti risparmio, le derivate sono queste:\n",
        "$\\frac{d\\text{J}}{dZ_2} = A_2-\\hat{Y} \\\\\n",
        "\\frac{d\\text{J}}{dW_2} = \\frac{1}{N} (A{_2}^T \\cdot \\frac{d\\text{J}}{dZ_2}) \\\\\n",
        "\\frac{d\\text{J}}{db_2} = \\frac{1}{N} \\sum_{i=1}^N(\\frac{d\\text{J}}{dZ_2}) \\\\\n",
        "\\frac{d\\text{J}}{dZ_1} = \\frac{d\\text{J}}{dZ_2} \\cdot W_2^T * g'(Z_1) \\\\\n",
        "\\frac{d\\text{J}}{dW_1} = \\frac{1}{N} (X^T \\cdot \\frac{d\\text{J}}{dZ_1})  \\\\\n",
        "\\frac{d\\text{J}}{db_1} = \\frac{1}{N} \\sum_{i=1}^N(\\frac{d\\text{J}}{dZ_1}) \\\\\n",
        "$\n",
        "<br><br>\n",
        "$g'(Z_1)$ è la derivata della funzione ReLu rispetto a $Z_1$, che è la seguente:\n",
        "<br><br>\n",
        "$$ g'(Z_1) =  \\begin{Bmatrix} \n",
        "0  \\ \\ \\ se \\ \\  z \\leq 0\n",
        "\\\\ \n",
        "1  \\ \\ \\ se \\ \\ z > 0\n",
        "\\end{Bmatrix}\n",
        "$$\n",
        "<br>\n",
        "Ora con queste equazioni davanti implemtiamo la backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ucj180fJ0jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_derivative(Z):\n",
        "  Z[Z<=0] = 0\n",
        "  Z[Z>0] = 1\n",
        "  return Z\n",
        "\n",
        "def back_propagation(X, W2, A1, A2, Y):\n",
        "  \n",
        "  m = A1.shape[1]\n",
        "  dZ2 = A2.reshape(-1,1)-Y.reshape(-1,1)\n",
        "  dW2 = np.dot(A1.T, dZ2)/m\n",
        "  db2 = np.sum(dZ2, axis=0)\n",
        "  \n",
        "  m = X.shape[1]\n",
        "  dZ1 = np.dot(dZ2.reshape(-1,1), W2.T)*relu_derivative(Z1)\n",
        "  dW1 = np.dot(X.T, dZ1)/m\n",
        "  db1 = np.sum(dZ2, axis=0)\n",
        "  \n",
        "  return dW1, db1, dW2, db2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgoIfNOTIqMK",
        "colab_type": "text"
      },
      "source": [
        "All'interno della funzione fit sostituiamo la funzione_magica_per_calcolare_le_derivate_parziali con la back_propagation che abbiamo appena definito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_Xqa1bj-ayP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(X, hidden, epochs=100, lr=0.01):\n",
        "     \n",
        "  for _ in range(epochs):\n",
        "    Y = predict(X, W1, b1, W2, b2)\n",
        "    dW1, db1, dW2, db2 = back_propagation(X, W2, A1, A2, Y)\n",
        "    W1+=lr*dW1\n",
        "    b1+=lr*db1\n",
        "    W2+=lr*dW2\n",
        "    b2+=lr*db2\n",
        "    \n",
        "  return W1, b1, W2, b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oni_Xi_2I26J",
        "colab_type": "text"
      },
      "source": [
        "Fantastico ! Manca un'ultima cosa, una funzione per inizializzare i valori dei coefficienti. Possiamo inizializzare i bias a 0, ma non i pesi ! Inizializzando i pesi a 0 le derivate parziali di tutti i pesi avranno lo stesso valore per tutte le iterazioni, questo vuol dire che il nostro modello non sarà migliore di un modello lineare. I pesi vanno inizializzati a valori casuali, nè troppo grandi nè troppo piccoli, infatti:\n",
        "* Se i pesi vengono inizializzati a valori troppo grandi,  nel caso di una rete abbastanza profonda il gradiente diventerà ancora più grande, a causa delle varie moltiplicazioni tra valori elevati alla quale è soggetto, questo problema è chiamato **Exploding Gradient Problem** (Problema dell'esplosione del Gradiente).\n",
        "* Se i pesi vengono inizializzati a valori troppo piccoli il problema è l'inverso, durante la backpropagation calcoleremo il gradiente eseguendo delle moltiplicazioni per valori molto piccoli, quindi questo tenderà a ridursi verso lo zero,  questo problema è chiamato **Vanishing Gradient Problem** (Problema della Scomparsa del Gradiente).\n",
        "\n",
        "Esistono tecniche sofisticate per l'inizializzazione intelligente dei pesi, ma nel nostro caso stiamo realizzando una rete neurale con un solo strato nascosto, quindi non dovremmo preoccuparci di questi problemi, selezioniamo i pesi da una distribuzione normale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3KtaM1EYM3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(input_size, hidden_size):\n",
        "    \n",
        "  W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
        "  b1 = np.zeros(hidden_size)\n",
        "  W2 = np.random.randn(hidden_size,1) * 0.01\n",
        "  b2 = np.zeros(1)\n",
        "  \n",
        "  return (W1, b1, W2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpmpEwJkML9l",
        "colab_type": "text"
      },
      "source": [
        "Aggiungiamo l'inizializzazione dei coefficienti all'interno della funzione fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BSuAbgpI2KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(X, hidden, epochs=100, lr=0.01):\n",
        "  \n",
        "  W1, b1, W2, b2 = init_weights(X.shape[1], hidden)\n",
        "   \n",
        "  for _ in range(epochs):\n",
        "    Y = predict(X, W1, b1, W2, b2)\n",
        "    dW1, db1, dW2, db2 = back_propagation(X, W2, A1, A2, Y)\n",
        "    W1+=lr*dW1\n",
        "    b1+=lr*db1\n",
        "    W2+=lr*dW2\n",
        "    b2+=lr*db2\n",
        "    \n",
        "  return W1, b1, W2, b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVzcPxXOMUKm",
        "colab_type": "text"
      },
      "source": [
        "Questo è tutto ! La nostra rete neurale fatta in casa è pronta, testiamola sul campo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gMCewFBAuLc",
        "colab_type": "text"
      },
      "source": [
        "## Testiamo la Rete Neurale\n",
        "In [questo tutorial](http://blog.profession.ai/la-tua-prima-classificazione/), abbiamo creato un modello di regressione logistica per riconosere tumori al seno maligni, partendo da informazioni estratte da esami radiologici. Utilizziamo lo stesso dataset, questa volta faremo totalmente a meno di scikit-learn. Importiamo il dataset direttamente dalla [Repository Github dei tutorial di Profession.ai](https://github.com/ProfAI/tutorials), per farlo possiamo utilizzare Pandas, una popolare libreria Python per l'analisi dati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1r4TDprok4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "f113ffe4-7a6e-41f6-ff52-e8f2bb876139"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "breast_cancer = pd.read_csv(\"breast_cancer.csv\", )\n",
        "breast_cancer.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  malignant\n",
              "0        17.99         10.38  ...                  0.11890          0\n",
              "1        20.57         17.77  ...                  0.08902          0\n",
              "2        19.69         21.25  ...                  0.08758          0\n",
              "3        11.42         20.38  ...                  0.17300          0\n",
              "4        20.29         14.34  ...                  0.07678          0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocpwzgg4bOPR",
        "colab_type": "text"
      },
      "source": [
        "Abbiamo in totale 31 colonne, cioè 30 features e un target, che è la colonna \"malignant\". Estraiamo features e target in array numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXxRz2rYN2cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = breast_cancer.drop(\"malignant\", axis=1).values\n",
        "y = breast_cancer[\"malignant\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T603f805bZvz",
        "colab_type": "text"
      },
      "source": [
        "Ora dobbiamo creare gli array per addestramento e predizione, facciamo la nostra personalissima funzione train_test_split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kMFsPEfFG-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3e7b2964-1788-4388-c0a9-1598949d8252"
      },
      "source": [
        "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
        "\n",
        "  if(random_state!=None):\n",
        "    np.random.seed(random_state)\n",
        "  \n",
        "  n = X.shape[0]\n",
        "\n",
        "  test_indices = np.random.choice(n, int(n*test_size), replace=False) # selezioniamo gli indici degli esempi per il test set\n",
        "  \n",
        "  # estraiamo gli esempi del test set\n",
        "  # in base agli indici\n",
        "  \n",
        "  X_test = X[test_indices]\n",
        "  y_test = y[test_indices]\n",
        "  \n",
        "  # creiamo il train set\n",
        "  # rimuovendo gli esempi del test set\n",
        "  # in base agli indici\n",
        "  \n",
        "  X_train = np.delete(X, test_indices, axis=0)\n",
        "  y_train = np.delete(y, test_indices, axis=0)\n",
        "\n",
        "  return (X_train, X_test, y_train, y_test )\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "print(\"Esempio in totale: %d\" % X.shape[0])\n",
        "print(\"Esempio per l'addestramento: %d\" % X_train.shape[0])\n",
        "print(\"Esempio per il test: %d\" % X_test.shape[0])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Esempio in totale: 569\n",
            "Esempio per l'addestramento: 399\n",
            "Esempio per il test: 170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4m6MdxEb1YK",
        "colab_type": "text"
      },
      "source": [
        "E' buona norma standardizzare o normalizzare i dati, per averli in una scala comune, questo può velocizzare anche di tanto la fase di addestramento. Optiamo per la normalizzazione (che è più semplice da implementare), la normalizzazione si esegue sottrando il valore minore e dividendo per la differenza tra il valore maggiore e il valore minore:\n",
        "<br><br>\n",
        "$$X_{norm} = \\frac{X - X_min}{X_max-X_min}$$\n",
        "<br><br>\n",
        "Ricorda che dobbiamo **sempre applicare le stesse trasformazioni ai dati di addestramento, a quelli di test, e in generale a tutti quelli che daremo in pasto alla nostra rete neurale**,  quindi calcoliamo massimo e minimo sul set di addestramento e usiamo questi valori per la normalizzazione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctarmj9OU1Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_max = X_train.max(axis=0)\n",
        "X_min = X_train.min(axis=0)\n",
        "\n",
        "X_train = (X_train - X_min)/(X_max-X_min)\n",
        "X_test = (X_test - X_min)/(X_max-X_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Ce6R5UyiGN",
        "colab_type": "text"
      },
      "source": [
        "## La Rete Neurale in una Classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15RKSF_Vq6Ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "  \n",
        "  \n",
        "  def __init__(self, hidden_layer_size=100):\n",
        "    \n",
        "    self.hidden_layer_size=hidden_layer_size\n",
        "    \n",
        "    \n",
        "  def _init_weights(self, input_size, hidden_size):\n",
        "    \n",
        "    self._W1 = np.random.randn(input_size, hidden_size)\n",
        "    self._b1 = np.zeros(hidden_size)\n",
        "    self._W2 = np.random.randn(hidden_size,1)\n",
        "    self._b2 = np.zeros(1)\n",
        "\n",
        "    \n",
        "  def _accuracy(self, y, y_pred):      \n",
        "    return np.sum(y==y_pred)/len(y)\n",
        "  \n",
        "  \n",
        "  def _log_loss(self, y_true, y_proba):\n",
        "    return -np.sum(np.multiply(y_true,np.log(y_proba))+np.multiply((1-y_true),np.log(1-y_proba)))/len(y_true)\n",
        "  \n",
        "  \n",
        "  def _relu(self, Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "  \n",
        "  def _sigmoid(self, Z):\n",
        "    return 1/(1+np.power(np.e,-Z))\n",
        "  \n",
        "  \n",
        "  def _relu_derivative(self, Z):\n",
        "    Z[Z<=0] = 0\n",
        "    Z[Z>0] = 1\n",
        "    return Z\n",
        "    \n",
        "               \n",
        "  def _forward_propagation(self, X):\n",
        "                     \n",
        "    Z1 = np.dot(X,self._W1)+self._b1\n",
        "\n",
        "    A1 = self._relu(Z1)\n",
        "    Z2 = np.dot(A1,self._W2)+self._b2\n",
        "    A2 = self._sigmoid(Z2)\n",
        "    \n",
        "    self._forward_cache = (Z1, A1, Z2, A2)\n",
        "\n",
        "    return A2.ravel()\n",
        "\n",
        "\n",
        "  def predict(self, X, return_proba=False):\n",
        "\n",
        "      proba = self._forward_propagation(X)\n",
        "\n",
        "      y = np.zeros(X.shape[0])\n",
        "      y[proba>=0.5]=1\n",
        "      y[proba<0.5]=0\n",
        "\n",
        "      if(return_proba):\n",
        "        return (y, proba)\n",
        "      else:\n",
        "        return proba\n",
        "\n",
        "\n",
        "  def predict_proba(self, X):         \n",
        "      return self._forward_propagation(X)\n",
        "                            \n",
        "      \n",
        "  def _back_propagation(self, X, y):\n",
        "  \n",
        "    Z1, A1, Z2, A2 = self._forward_cache\n",
        "                   \n",
        "    m = A1.shape[1]\n",
        "    \n",
        "    dZ2 = A2-y.reshape(-1,1)\n",
        "    dW2 = np.dot(A1.T, dZ2)/m\n",
        "    db2 = np.sum(dZ2, axis=0)/m\n",
        "\n",
        "    dZ1 = np.dot(dZ2, self._W2.T)*self._relu_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1)/m\n",
        "    db1 = np.sum(dZ1, axis=0)/m\n",
        "    \n",
        "    return dW1, db1, dW2, db2\n",
        "           \n",
        "               \n",
        "  def fit(self, X, y, epochs=200, lr=0.01):\n",
        "     \n",
        "    self._init_weights(X.shape[1], self.hidden_layer_size)\n",
        "      \n",
        "    for _ in range(epochs):\n",
        "      Y = self._forward_propagation(X)\n",
        "      dW1, db1, dW2, db2 = self._back_propagation(X, y)\n",
        "      self._W1-=lr*dW1\n",
        "      self._b1-=lr*db1\n",
        "      self._W2-=lr*dW2\n",
        "      self._b2-=lr*db2\n",
        "               \n",
        "\n",
        "  def evaluate(self, X, y):\n",
        "    y_pred, proba = self.predict(X, return_proba=True)\n",
        "    accuracy = self._accuracy(y, y_pred)\n",
        "    log_loss = self._log_loss(y, proba)\n",
        "    return (accuracy, log_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI6vYq7l3Gq6",
        "colab_type": "code",
        "outputId": "ca501525-7926-4806-a850-9c803e1f90df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = NeuralNetwork()\n",
        "model.fit(X_train, y_train, epochs=500, lr=0.01)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9529411764705882, 0.10412022044693808)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9pC8PmWynVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}